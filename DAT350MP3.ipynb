{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, you are tasked to imagine yourself as a machine learning engineer at a company. Your boss, a respected but somewhat weary, expert in the field has handed you the dataset from step 1 and has asked you to clean/prepare the data for machine learning and then to train four different machine learning models that make a predictions from that data. Your boss will also want information regarding the accuracy of the models. Your boss will also want to hear a discussion on whether you think your model has too much bias or variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What features/columns had a relatively even or normal distribution? Which features/columns did not?\n",
    "\n",
    "The HP, Attack, Defense, Special Attack, Special Defense and Speed columns all had normal distributions. While the column, Pokemon number has a relatively even distribution.\n",
    "\n",
    "2.  How did you handle missing values? Why did you do this method as opposed to others?\n",
    "\n",
    "The way I handled my missing values was by removing the NAs or blank values and filling them with the mean or median value from that specific column. I chose to do this method because it kept the data simple and made sure they all followed the same trends. It also kept the data reasonable because If I happened to only fikl these values with kets say 0, my data would be very skewed and innacurate.\n",
    "\n",
    "3. How did you encode your categorical data? Why did you do this method as opposed to others?\n",
    "\n",
    "I encoded my categorical data by using one - hot encoding because this method helped me to convert my categorical data into a numerical format without any trouble. \n",
    "\n",
    "4.  How did you handle removing outliers? Why did you use this method as opposed to others?\n",
    "\n",
    "I handled my outliers by using statistical methodes: Z score and IQR as we have reviewed in class. I had a couple of outliers that were extreme and if left alone could have changed the outcomes of my machine learning tests, so this method was the best way to counter that.\n",
    "\n",
    "5. How did you normalize/standardize the data? Why did you use this method as opposed to others?\n",
    "\n",
    "My data was standardized using z-score normaalization and I chose this because it helped me scale my data to where the mean was 0 and my standard deviation is 1, which overall helped the performance of my machine learning tests.\n",
    "\n",
    "\n",
    "6. How did each model perform? Which performed the best?\n",
    "\n",
    "\n",
    "\n",
    "7. Did any models seem to have a relatively high amount of bias (underfitting)? Variance (overfitting)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start by loading the dataset and performing some initial exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
      "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
      "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
      "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
      "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
      "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
      "\n",
      "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
      "0       65       65     45           1      False  \n",
      "1       80       80     60           1      False  \n",
      "2      100      100     80           1      False  \n",
      "3      122      120     80           1      False  \n",
      "4       60       50     65           1      False  \n",
      "\n",
      "Missing values:\n",
      " #               0\n",
      "Name            0\n",
      "Type 1          0\n",
      "Type 2        512\n",
      "Total           0\n",
      "HP              0\n",
      "Attack          0\n",
      "Defense         0\n",
      "Sp. Atk         0\n",
      "Sp. Def         0\n",
      "Speed           0\n",
      "Generation      0\n",
      "Legendary       0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics:\n",
      "                  #        Total           HP       Attack      Defense  \\\n",
      "count  1104.000000  1104.000000  1104.000000  1104.000000  1104.000000   \n",
      "mean    503.437500   439.358696    70.655797    80.220109    74.507246   \n",
      "std     292.665209   119.710538    26.448074    32.103379    30.715728   \n",
      "min       1.000000   175.000000     1.000000     5.000000     5.000000   \n",
      "25%     254.750000   330.000000    50.000000    55.000000    50.000000   \n",
      "50%     492.500000   460.000000    68.000000    76.000000    70.000000   \n",
      "75%     749.250000   520.000000    85.000000   100.000000    90.250000   \n",
      "max    1025.000000   780.000000   255.000000   190.000000   230.000000   \n",
      "\n",
      "           Sp. Atk      Sp. Def        Speed   Generation  \n",
      "count  1104.000000  1104.000000  1104.000000  1104.000000  \n",
      "mean     72.951993    72.000906    68.994565     4.640399  \n",
      "std      32.415431    27.315772    29.724086     2.598249  \n",
      "min      10.000000    20.000000     5.000000     1.000000  \n",
      "25%      50.000000    50.000000    45.000000     3.000000  \n",
      "50%      65.000000    70.000000    65.000000     4.000000  \n",
      "75%      95.000000    90.000000    90.000000     7.000000  \n",
      "max     194.000000   230.000000   200.000000     9.000000  \n",
      "\n",
      "Distribution of 'Type 1':\n",
      " Type 1\n",
      "Water       140\n",
      "Normal      123\n",
      "Grass       108\n",
      "Bug          89\n",
      "Fire         70\n",
      "Psychic      70\n",
      "Electric     67\n",
      "Rock         61\n",
      "Dark         48\n",
      "Dragon       45\n",
      "Ghost        44\n",
      "Ground       42\n",
      "Fighting     42\n",
      "Poison       42\n",
      "Steel        41\n",
      "Ice          31\n",
      "Fairy        29\n",
      "Flying       10\n",
      "bug           1\n",
      "ice           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'Type 2':\n",
      " Type 2\n",
      "Flying      110\n",
      "Psychic      47\n",
      "Poison       44\n",
      "Ground       40\n",
      "Fairy        40\n",
      "Fighting     40\n",
      "Dragon       37\n",
      "Steel        34\n",
      "Ghost        32\n",
      "Grass        31\n",
      "Dark         28\n",
      "Water        22\n",
      "Ice          20\n",
      "Fire         18\n",
      "Rock         16\n",
      "Normal       13\n",
      "Electric     10\n",
      "Bug           9\n",
      "ice           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pokemon_df = pd.read_csv(\"Pokemon.csv\")\n",
    "\n",
    "print(pokemon_df.head())\n",
    "\n",
    "print(\"\\nMissing values:\\n\", pokemon_df.isnull().sum())\n",
    "\n",
    "print(\"\\nSummary statistics:\\n\", pokemon_df.describe())\n",
    "\n",
    "print(\"\\nDistribution of 'Type 1':\\n\", pokemon_df['Type 1'].value_counts())\n",
    "print(\"\\nDistribution of 'Type 2':\\n\", pokemon_df['Type 2'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's proceed with the data cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df['Type 2'].fillna('None', inplace=True)\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_scores = zscore(pokemon_df.select_dtypes(include='number'))\n",
    "abs_z_scores = abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "pokemon_df = pokemon_df[filtered_entries]\n",
    "\n",
    "pokemon_df = pd.get_dummies(pokemon_df, columns=['Type 1', 'Type 2'])\n",
    "\n",
    "X = pokemon_df.drop(columns=['#', 'Name'])\n",
    "y = pokemon_df['HP']  \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's train the machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n",
      "Performance of Linear Regression:\n",
      "R squared (Train): 1.0000, R squared (Test): 1.0000\n",
      "Root Mean Squared Error (Train): 0.0000, Root Mean Squared Error (Test): 0.0082\n",
      "Mean Absolute Error (Train): 0.0000, Mean Absolute Error (Test): 0.0006\n",
      "\n",
      "Training Decision Tree Regression...\n",
      "Performance of Decision Tree Regression:\n",
      "R squared (Train): 1.0000, R squared (Test): 0.9997\n",
      "Root Mean Squared Error (Train): 0.0000, Root Mean Squared Error (Test): 0.3699\n",
      "Mean Absolute Error (Train): 0.0000, Mean Absolute Error (Test): 0.0708\n",
      "\n",
      "Training Random Forest Regression...\n",
      "Performance of Random Forest Regression:\n",
      "R squared (Train): 0.9999, R squared (Test): 0.9999\n",
      "Root Mean Squared Error (Train): 0.2489, Root Mean Squared Error (Test): 0.2786\n",
      "Mean Absolute Error (Train): 0.0492, Mean Absolute Error (Test): 0.1018\n",
      "\n",
      "Training Gradient Boosting Regression...\n",
      "Performance of Gradient Boosting Regression:\n",
      "R squared (Train): 1.0000, R squared (Test): 1.0000\n",
      "Root Mean Squared Error (Train): 0.0328, Root Mean Squared Error (Test): 0.1009\n",
      "Mean Absolute Error (Train): 0.0155, Mean Absolute Error (Test): 0.0292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regression': DecisionTreeRegressor(),\n",
    "    'Random Forest Regression': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regression': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"Performance of {name}:\")\n",
    "    print(f\"R squared (Train): {r2_train:.4f}, R squared (Test): {r2_test:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (Train): {rmse_train:.4f}, Root Mean Squared Error (Test): {rmse_test:.4f}\")\n",
    "    print(f\"Mean Absolute Error (Train): {mae_train:.4f}, Mean Absolute Error (Test): {mae_test:.4f}\")\n",
    "\n",
    "    if r2_train < 0.7:\n",
    "        print(\"The model seems to have high bias (underfitting).\")\n",
    "    elif r2_train > 0.9 and (r2_train - r2_test) > 0.1:\n",
    "        print(\"The model seems to have high variance (overfitting).\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
